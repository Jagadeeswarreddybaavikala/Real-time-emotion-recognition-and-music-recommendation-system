![banner](https://capsule-render.vercel.app/api?type=waving&color=gradient&height=160&section=header&text=Emotion%20Recognition%20+%20Music%20AI&fontSize=34&animation=twinkling)




ğŸµ Real-Time Emotion Recognition & Music Recommendation System

![Python](https://img.shields.io/badge/Python-3.x-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-green)
![Platform](https://img.shields.io/badge/Platform-macOS%20%7C%20Windows%20%7C%20Linux-lightgrey)
![Status](https://img.shields.io/badge/Status-Active-brightgreen)

A machine learningâ€“powered system that detects human emotions in real time using facial expressions and automatically recommends music based on the detected emotion.
This project combines computer vision, deep learning, and intelligent music mapping to create an interactive, mood-aware experience.

ğŸš€ Features

âœ”ï¸ Real-time face detection using webcam
âœ”ï¸ Deep learning model trained on FER-2013 dataset
âœ”ï¸ Emotion classification (Happy, Sad, Angry, Neutral, etc.)
âœ”ï¸ Music recommendation based on emotional state
âœ”ï¸ Visualization of training results (accuracy, loss graphs)
âœ”ï¸ Modular and scalable codebase
âœ”ï¸ Fully reproducible environment using requirements.txt

ğŸ§  Supported Emotions
Emotion	Possible Music Type
ğŸ˜Š Happy	Pop / Energetic / EDM
ğŸ˜¢ Sad	Calm / LoFi / Relaxation
ğŸ˜¡ Angry	Rock / Metal / Workout
ğŸ˜ Neutral	Ambient / Soft Instrumental
ğŸ˜² Surprise	Trending playlist (optional)

You can modify mappings in spotify_music.py.

ğŸ§± Tech Stack
Category	Tools
Language	Python 3
ML Framework	TensorFlow / Keras
Computer Vision	OpenCV
Data Handling	NumPy, Pandas
Visualization	Matplotlib / Seaborn
Deployment Mode	Local Script (Future: Streamlit / Flask UI)
ğŸ“ Folder Structure
Real-time-emotion-recognition-and-music-recommendation-system/
â”œâ”€â”€ src/                   
â”œâ”€â”€ data/                      
â”œâ”€â”€ models/                   
â”œâ”€â”€ project_results/        
â”œâ”€â”€ enhanced_emotion_detection.py
â”œâ”€â”€ train_fer2013_model.py
â”œâ”€â”€ run_real_detection.py
â”œâ”€â”€ run_trained_app.py
â”œâ”€â”€ spotify_music.py
â”œâ”€â”€ plot_training_history.py
â”œâ”€â”€ generate_report.py
â”œâ”€â”€ test_classification.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

ğŸ›  Installation
1ï¸âƒ£ Clone the repository
git clone https://github.com/Jagadeeswarreddybaavikala/Real-time-emotion-recognition-and-music-recommendation-system.git
cd Real-time-emotion-recognition-and-music-recommendation-system

2ï¸âƒ£ Create a virtual environment
python -m venv venv
source venv/bin/activate   # macOS / Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

ğŸ§ª Train the Model
python train_fer2013_model.py


This script will:

Train the CNN on FER-2013

Save trained model in models/

Generate logs in project_results/

Optional: visualize training:

python plot_training_history.py

ğŸ¥ Run Real-Time Detection
python run_real_detection.py


This opens the webcam, detects the face, and displays live emotion predictions.

ğŸ§ Run Full Emotionâ†’Music System
python run_trained_app.py


This will:

Detect your face

Predict your emotion

Recommend music using logic in spotify_music.py

(Music source can be Spotify API, YouTube links, local MP3s, etc.) 

ğŸ”® Future Enhancements

ğŸ”¹ Deploy as a web app using Flask / Streamlit
ğŸ”¹ Add voice emotion + sentiment analysis
ğŸ”¹ Use transfer learning (ResNet / EfficientNet)
ğŸ”¹ Enable Spotify OAuth live control
ğŸ”¹ Add multi-user emotion awareness

ğŸ‘¤ Author

BAAVIKALA JAGADEESWAR REDDY
ğŸ“ SDE | Developer | Innovator
ğŸ”— GitHub: Jagadeeswarreddybaavikala

ğŸ“œ License

This project is open-source and available under the MIT License.

MIT License â€” feel free to use, modify, and improve.

â­ If you like this project, please star the repository ğŸ’™
